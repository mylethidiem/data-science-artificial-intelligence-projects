{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mylethidiem/artificial-intelligence-projects/blob/main/Architecture%20Project%20Gradient%20Vanishing%20in%20MLP/7_GradientNorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "HItsinp0SFqA"
   },
   "source": [
    "## **0. Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "bb96f0ec-3525-4e79-9ad1-8e95c15a9cf2"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt # truc quan hoa\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import FashionMNIST #download fashion mnist data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3ehfc2p0vqq",
    "outputId": "5b6b2842-59d7-4446-d91a-fdb785f7aefb"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "Mw6hLiNAugrD"
   },
   "source": [
    "## **1. Prepare dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c73f1e96-b8ea-4b8f-b4f3-9b3f27b42acd",
    "outputId": "c501d894-fef0-42a3-f6a6-21c0e2f7590e"
   },
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7RaVrLgpMx3",
    "outputId": "64ee93fc-7784-4f09-e509-7392f0459569"
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "train_size = int(train_ratio * len(train_dataset)) #90%\n",
    "val_size = len(train_dataset) - train_size #10%\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Train size: {len(train_subset)}\")\n",
    "print(f\"Validation size: {len(val_subset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "75eeaa46"
   },
   "source": [
    "## **2. Build MLP network `with Gradient Norm`**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "U5cOsIseONYO"
   },
   "outputs": [],
   "source": [
    "# Custom Gradient Normalization Layer\n",
    "# Use Pytorch's autograd mechanism to normalize gradients during backpropagation phase\n",
    "class GradientNormalization(torch.autograd.Function):\n",
    "  @staticmethod\n",
    "  def forward(ctx, input):\n",
    "    # Forward pass: pass input unchanged\n",
    "    ctx.save_for_backward(input)\n",
    "    return input\n",
    "\n",
    "  @staticmethod\n",
    "  def backward(ctx, grad_output):\n",
    "    # Normalize the gradient\n",
    "    mean = torch.mean(grad_output)\n",
    "    std = torch.std(grad_output)\n",
    "    avoid_division_by_zero = 1e-6\n",
    "    grad_input = (grad_output - mean) / (std + avoid_division_by_zero)\n",
    "    return grad_input\n",
    "\n",
    "# Wrapper Module for GradientNormalization\n",
    "class GradientNormalizationLayer(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(GradientNormalizationLayer, self).__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return GradientNormalization.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "uthwgJntUNpq"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, hidden_dims)\n",
    "        self.layer2 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.layer3 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.layer4 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.layer5 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.layer6 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.layer7 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.output = nn.Linear(hidden_dims, output_dims)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.05)\n",
    "                nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = GradientNormalizationLayer()(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = GradientNormalizationLayer()(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = GradientNormalizationLayer()(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = GradientNormalizationLayer()(x)\n",
    "\n",
    "        x = self.layer5(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = GradientNormalizationLayer()(x)\n",
    "\n",
    "        x = self.layer6(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = GradientNormalizationLayer()(x)\n",
    "\n",
    "        x = self.layer7(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = GradientNormalizationLayer()(x)\n",
    "\n",
    "        out = self.output(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "589bb0df"
   },
   "outputs": [],
   "source": [
    "input_dims = 784 #28x28 pixel = 784 pixel\n",
    "hidden_dims = 128\n",
    "output_dims = 10 #10 class\n",
    "lr = 1e-2\n",
    "model = MLP(input_dims, hidden_dims, output_dims).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "lBS7q-JzwFgC"
   },
   "source": [
    "## **3. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21211483-aeed-4beb-aeea-d1e58ae7baf9",
    "outputId": "f9926f63-2500-4cfc-9325-8ee13eca0a84"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "train_loss_lst =[]\n",
    "train_acc_lst = []\n",
    "val_loss_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  train_loss = 0\n",
    "  train_acc = 0\n",
    "  count = 0\n",
    "  model.train()\n",
    "  for X_train, y_train in train_loader:\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "    train_acc += (torch.argmax(outputs,1) == y_train).sum().item()\n",
    "    count += len(y_train)\n",
    "  train_loss /= len(train_loader)\n",
    "  train_loss_lst.append(train_loss)\n",
    "  train_acc /= count\n",
    "  train_acc_lst.append(train_acc)\n",
    "\n",
    "  val_loss = 0.0\n",
    "  val_acc = 0.0\n",
    "  count = 0\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for X_val, y_val in val_loader:\n",
    "      X_val = X_val.to(device)\n",
    "      y_val = y_val.to(device)\n",
    "      outputs = model(X_val)\n",
    "      loss = criterion(outputs, y_val)\n",
    "      val_loss += loss.item()\n",
    "      val_acc += (torch.argmax(outputs,1) == y_val).sum().item()\n",
    "      count += len(y_val)\n",
    "  val_loss /= len(val_loader)\n",
    "  val_loss_lst.append(val_loss)\n",
    "  val_acc /= count\n",
    "  val_acc_lst.append(val_acc)\n",
    "\n",
    "  print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f},Train_Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f} , Val_Acc:{val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "321d7070-b736-4ebb-94fa-59cd37ff50b3",
    "outputId": "238e868b-1859-470b-af50-db1a383d19a2"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "ax[0, 0].plot(train_loss_lst, color='green')\n",
    "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "\n",
    "ax[0, 1].plot(val_loss_lst, color='orange')\n",
    "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
    "ax[0, 1].set_title('Validation Loss')\n",
    "\n",
    "ax[1, 0].plot(train_acc_lst, color='green')\n",
    "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "ax[1, 1].plot(val_acc_lst, color='orange')\n",
    "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "CY9OpDyiPL2V"
   },
   "source": [
    "## **4. Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VC8cygPWPKy6",
    "outputId": "b2fb785f-4578-4783-9ff3-2388bab5bae4"
   },
   "outputs": [],
   "source": [
    "test_target = []\n",
    "test_predict = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for X_test, y_test in test_loader:\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    outputs = model(X_test)\n",
    "\n",
    "    test_target.append(y_test.cpu())\n",
    "    test_predict.append(outputs.cpu())\n",
    "\n",
    "test_target = torch.cat(test_target, dim=0) #ghép theo chiều thứ nhất chiều batch(chiều dọc)\n",
    "test_predict = torch.cat(test_predict, dim=0)\n",
    "\n",
    "test_acc = (torch.argmax(test_predict,1)==test_target).sum().item()/len(test_target)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsTDEJ92P6Pa",
    "outputId": "a8d23814-138c-422d-fdc6-dbbb70ffbcc9"
   },
   "outputs": [],
   "source": [
    "val_label = []\n",
    "val_predict = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for X_val, y_val in val_loader:\n",
    "    X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "    output = model(X_val)\n",
    "\n",
    "    val_label.append(y_val.cpu())\n",
    "    val_predict.append(output.cpu())\n",
    "\n",
    "  val_label = torch.cat(val_label, dim=0)\n",
    "  val_predict = torch.cat(val_predict, dim=0)\n",
    "  val_acc = (torch.argmax(val_predict, dim=1) == val_label).sum().item()/len(val_label)\n",
    "\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
